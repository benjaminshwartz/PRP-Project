{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8df900e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Tuple\n",
    "import boto3 as boto\n",
    "import random\n",
    "import _pickle as cPickle\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import os\n",
    "import torchvision.transforms as T \n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f66587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = read_image(\"patient2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4248185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 620, 488])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b803cc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132.50037017451083"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40089312/302560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef71fd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40089312, 34832137, 28956982, 76746330])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53cf20ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302560"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.size()[1] * a.size()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef46f20c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([132.5004, 115.1247,  95.7066, 253.6566])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=(1,2))/(a.size()[1] * a.size()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "263cc0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([132.5004, 115.1247,  95.7066, 253.6565])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a.float(),dim = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bf71036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([77.3145, 65.6562, 64.2510, 18.4600])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(a.float(),dim = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8213f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SINGLE GPU INSTANCE CAPABILITIES ONLY. WILL HAVE TO UPDATE FOR MULTIGPU\n",
    "class PRPDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, patient_ids: list,patient_labels: dict, num_classification_output: int,path: str, size: tuple):\n",
    "        \n",
    "        #dictionary of where patient ids are keys and rating is value\n",
    "        self.patient_labels = patient_labels\n",
    "        \n",
    "        #list of patient ids\n",
    "        self.patient_ids = patient_ids\n",
    "        \n",
    "        #path\n",
    "        self.path = path\n",
    "        \n",
    "        self.num_classification_output = num_classification_output\n",
    "        \n",
    "        self.resize = v2.Resize(size)\n",
    "        self.to_image = v2.ToImage()\n",
    "        self.to_Dtype = v2.ToDtype(torch.float32, scale=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "    \n",
    "    def __getitem__(self,idx:int):\n",
    "        \n",
    "        #indexing via list\n",
    "        patient = self.patient_ids[idx]\n",
    "        \n",
    "        #pulling image from storage bucket and un-pickling it\n",
    "        #THIS MAY HAVE TO BE CHANGED DEPENDING ON HOW EXACTLY THE IMAGES ARE STORED\n",
    "        #image = cPickle.load(open(f'{self.path}/{patient}/image'),\"rb\")\n",
    "        image = read_image(f'{patient}.png')\n",
    "        \n",
    "        #calculating mean and standard deviation along channels for one photo\n",
    "        image = self.resize(image)\n",
    "        image = self.to_image(image)\n",
    "        image = self.to_Dtype(image)\n",
    "        mean,std = self.mean_std(image)\n",
    "        norm = v2.Normalize(mean=mean,std = std)\n",
    "        image = norm(image)\n",
    "        \n",
    "        #transformation used on each image \n",
    "        #Note that mean/std are vectors of len(4) for the alpha,RBG channels\n",
    "        #self.transforms = v2.Compose([\n",
    "            #v2.Resize(size),\n",
    "            #v2.ToImage(), \n",
    "            #v2.ToDtype(torch.float32, scale=True),\n",
    "            #v2.Normalize(mean = mean,std = std)\n",
    "        #])\n",
    "        \n",
    "        #Resize image\n",
    "        #resized_image = self.transforms(image)\n",
    "        #print(f\"IMAGE SUM: {torch.sum(resized_image)}\")\n",
    "        \n",
    "        #Get label\n",
    "        label_tensor = [0 for _ in range(self.num_classification_output)]\n",
    "        label = torch.tensor(self.patient_labels[patient])\n",
    "        label_tensor[label-1] = 1\n",
    "        label_tensor = torch.tensor(label_tensor)\n",
    "        \n",
    "        return image, label_tensor\n",
    "    \n",
    "    #Should maybe try to calculate mean_std deviation once prior to running script and store data\n",
    "    #So that we do not have to rerun this step everytime the script is rerun \n",
    "    #\n",
    "    #Note we are calculating the mean of pixel average for each the image\n",
    "    #And the mean of the pixel std. dev for each the images\n",
    "    def mean_std(self,image):\n",
    "        \n",
    "        a = torch.mean(image,axis=(1,2))\n",
    "        b = torch.mean(image,axis=(1,2))\n",
    "        \n",
    "        return a,b\n",
    "    \n",
    "def sequential_train_test_split(split: tuple, labels:dict):\n",
    "    \n",
    "    #Getting number of patients \n",
    "    num_patients = len(labels.keys())\n",
    "    #Getting how patients to include in training\n",
    "    training_num = int(split[0] * num_patients)\n",
    "    #creating training set\n",
    "    training_patients = labels.keys()[:training_num]\n",
    "    #Creating Test set \n",
    "    testing_patients = labels.keys()[training_num:]\n",
    "\n",
    "    return training_patients, testing_patients\n",
    "\n",
    "def random_train_test_split(split: tuple, labels:dict):\n",
    "    \n",
    "    #Converting label list to label set to use subtraction\n",
    "    patient_set = set(labels.keys())\n",
    "    \n",
    "    #Traning set\n",
    "    training_patients = set()\n",
    "\n",
    "    #calculating number of patients\n",
    "    num_patients = len(labels.keys())\n",
    "    \n",
    "    #calculating number of patients in training set\n",
    "    training_num = int(split[0] * num_patients)\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    #looping number of patients \n",
    "    while i != training_num:\n",
    "        #Choosing a patient from the list of left over patients not yet chosen\n",
    "        curr_patient = random.choice(list(patient_set-training_patients))\n",
    "        #adding patient to list of training patient\n",
    "        training_patients.add(curr_patient)\n",
    "        #Iterating\n",
    "        i += 1\n",
    "\n",
    "    #Getting test set\n",
    "    test_patients = patient_set - training_patients\n",
    "    #print(list(training_patients))\n",
    "    #print(list(test_patients))\n",
    "\n",
    "    #Reconverting back to list \n",
    "    return list(training_patients), list(test_patients)\n",
    "\n",
    "def get_train_test_dataset(dict_path: str, data_path: str, num_class_output: int,size: tuple ,sequential: bool, split:tuple):\n",
    "    \n",
    "    #Getting dictionary that has patient keys and scores as values\n",
    "    #Path may need to be changed\n",
    "    patient_labels = cPickle.load(open(dict_path, 'rb'))\n",
    "    \n",
    "    #If want the data to be split sequentially (i.e in order)\n",
    "    if sequential:\n",
    "        train, test = sequential_train_test_split(split,patient_labels)\n",
    "    else:\n",
    "    #If want data split randomly (More Likely used)\n",
    "        train, test = random_train_test_split(split,patient_labels)\n",
    "    \n",
    "    \n",
    "    #Creating PRPDataSet objects for both train and test sets\n",
    "    train_set = PRPDataSet(train,patient_labels,num_class_output,data_path,size)\n",
    "    test_set = PRPDataSet(test,patient_labels,num_class_output,data_path,size)\n",
    "    \n",
    "    return train_set,test_set\n",
    "\n",
    "def PRPDataLoader(dict_path: str, data_path: str, num_class_output: int,size: tuple,sequential: bool, split: tuple, batch: int):\n",
    "    \n",
    "    #Getting PRPDataSet objects for both rain and test sets \n",
    "    train_set, test_set = get_train_test_dataset(dict_path, data_path, num_class_output, size ,sequential, split)\n",
    "    #print(f\"LEN TRAIN: {len(train_set)}\")\n",
    "    #Creating DataLoader with Train and Set Data sets\n",
    "    train_generator = DataLoader(train_set, batch_size = batch, shuffle = True)\n",
    "    test_generator = DataLoader(test_set, batch_size = batch, shuffle = True)\n",
    "    \n",
    "    #print(f\"TRAIN GEN LEN: {len(train_generator)}\")\n",
    "    #print(f\"TEST GEN LEN: {len(test_generator)}\")\n",
    "    \n",
    "    return train_generator,test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1095c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not set up for multi-gpu running, need to add things to get that ready \n",
    "#Also would like to add confusion matrix output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "import _pickle as cPickle\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import boto3 as boto\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "#class Trainer:\n",
    "    \n",
    "    #def __init___(self, \n",
    "                  #model : torch.nn.Module,\n",
    "                  #optimizer: torch.optim.Optimizer,\n",
    "                  #loss_fn: torch.nn,\n",
    "                  #save_interval: int, \n",
    "                  #metric_interval: int,\n",
    "                  #train_data: DataLoader,\n",
    "                  #validation_data: DataLoader = None, \n",
    "                  #test_data: DataLoader = None,\n",
    "                  #save_path: str = None): \n",
    "        \n",
    "        #Setting all variables equal to a local counterpart \n",
    "        #self.model = model\n",
    "        #self.optimizer = optimizer\n",
    "        #self.loss_fn = loss_fn\n",
    "        #self.save_interval = save_interval\n",
    "        #self.metric_interval = metric_interval\n",
    "        #self.train_data = train_data\n",
    "        #self.validation_data = validation_data\n",
    "        #self.test_data = test_data\n",
    "        #self.save_path = save_path\n",
    "        \n",
    "        #going to be used in evaluating function to decrease latency of model \n",
    "        #self.curr_predictions = []\n",
    "        #self.curr_labels = []\n",
    "        \n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 loss_fn: torch.nn.Module,\n",
    "                 save_interval: int,\n",
    "                 metric_interval: int,\n",
    "                 train_data: DataLoader,\n",
    "                 validation_data: DataLoader = None,\n",
    "                 test_data: DataLoader = None,\n",
    "                 save_path: str = None):\n",
    "        \n",
    "        # Setting all variables equal to a local counterpart\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.save_interval = save_interval\n",
    "        self.metric_interval = metric_interval\n",
    "        self.train_data = train_data\n",
    "        self.validation_data = validation_data\n",
    "        self.test_data = test_data\n",
    "        self.save_path = save_path\n",
    "\n",
    "        # Going to be used in evaluating function to decrease latency of model\n",
    "        self.curr_predictions = []\n",
    "        self.curr_labels = []\n",
    "        \n",
    "    def _run_batch(self,batch: torch.Tensor, batch_labels: torch.Tensor):\n",
    "        #Setting current gradient to zero for new batch\n",
    "        self.optimizer.zero_grad()\n",
    "        #Running model on current batch\n",
    "        #print(\"running _run_batch\")\n",
    "        pred_output = self.model(batch)\n",
    "        #print(\"Done running batch\")\n",
    "        #Appending predicted values to list for evaluation \n",
    "        self.curr_predictions.append(pred_output)\n",
    "        #Appending label values to list for evaluation\n",
    "        self.curr_labels.append(batch_labels)\n",
    "        \n",
    "        #Computing loss \n",
    "        #print(f\"PRED OUTPUT: {pred_output}\")\n",
    "        #print(f\"BATCH LABEL: {batch_labels}\")\n",
    "        loss = self.loss_fn(pred_output.float(),batch_labels.float())\n",
    "        \n",
    "        #Computing gradient for each parameter in model\n",
    "        loss.backward()\n",
    "        #grads = [p.grad for p in self.model.parameters()]\n",
    "        #print(grads[:50])\n",
    "        #Gradient descent \n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def _run_epoch(self, epoch:int):\n",
    "        #Including epoch num in init bc likely will want to print out at somepoint to see how quickly model runs\n",
    "        #Setting model to train\n",
    "        \n",
    "        self.model.train()\n",
    "        #Re-initiating prediction/label accumulator for evaluation of specific epoch\n",
    "        \n",
    "        self.curr_predictions = []\n",
    "        self.curr_labels = []\n",
    "        \n",
    "        #Looping over each training batch\n",
    "        #print(\"training model\")\n",
    "        for batch_tensor, batch_labels in self.train_data:\n",
    "            \n",
    "            #print(f\"batch_tensor: {batch_tensor.shape}\")\n",
    "            #print(f\"batch_labels: {batch_labels.shape}\")\n",
    "            #print(batch_tensor)\n",
    "            \n",
    "            #Running gradient descent on each batch\n",
    "            self._run_batch(batch_tensor,batch_labels)\n",
    "        #print(\"done training model\")\n",
    "        #print(\"exiting _run_epoch\")\n",
    "    \n",
    "    #TODO: FINISH how to save to server\n",
    "    def _save_checkpoint(self, epoch: int):\n",
    "        #Getting the model weights at particular checkpoint\n",
    "        #print(\"in save_checkpoint method\")\n",
    "        checkpoint_model = self.model.state_dict()\n",
    "        #print(\"after getting the state-dict\")\n",
    "        #Pickling model into checkpoint_{epoch} file\n",
    "        #Note that pickle.dump saves model in local directory\n",
    "        #Need to delete after dump and upload\n",
    "        torch.save(checkpoint_model,f'checkpoint_{epoch}.pt')\n",
    "        #cPickle.dump(checkpoint_model, open(f'checkpoint_{epoch}.pt', 'wb'))\n",
    "        #print(\"after pickle dump\")\n",
    "        #NEED TO FINISH SAVING TO FOLDER OF DICTIONARIES\n",
    "        \n",
    "    \n",
    "    def train(self, num_epochs:int):\n",
    "        \n",
    "        #Looping over number of epochs\n",
    "        for epoch in range(1,num_epochs+1):\n",
    "            \n",
    "            #Running an epoch\n",
    "            print(f\"running {epoch} epoch\")\n",
    "            self._run_epoch(epoch)\n",
    "            \n",
    "            #print(\"outside self.save_interval\")\n",
    "            #Code to save the model every save_interval   \n",
    "            if self.save_interval > 0 and epoch % self.save_interval == 0:\n",
    "                #print(\"In save_interval\")\n",
    "                self._save_checkpoint(epoch)\n",
    "            #Saving the last model\n",
    "            elif epoch == num_epochs:\n",
    "                self._save_checkpoint(epoch)\n",
    "\n",
    "            #Evaluating model every metric_interval\n",
    "            #print(\"outside self.metric_interval\")\n",
    "            if self.metric_interval > 0 and epoch % self.metric_interval == 0:\n",
    "                #Decreases time bc saved inferences for training data in list\n",
    "                #Evaluating Training set\n",
    "                self._evaluate(None)\n",
    "                #Will have to do inference for test set\n",
    "                if self.test_data != None:\n",
    "                    #Evaluating test set\n",
    "                    self._evaluate(self.test_data)\n",
    "                    #Resetting the model to train \n",
    "                    self.model.train()\n",
    "                \n",
    "    def _evaluate(self, dataloader: DataLoader = None):\n",
    "        #Converting to torch.no_grad to prevent gradient calculation\n",
    "        with torch.no_grad():\n",
    "            #Set model to evaluation\n",
    "            self.model.eval()\n",
    "            #If dataloader none, it means we are looking at the current training set accuracy \n",
    "            if dataloader == None:\n",
    "                #Using already predicted values that we accumulated during the training \n",
    "                #This obviously is a lower bound on the accuracy of our model on the training set\n",
    "                #However, transformer latency is extremely large so this will decrease training time overall\n",
    "                #Also we don't care about the actual training accuracy, we only care about the overall trends of \n",
    "                #training accuracy\n",
    "                predict_output = torch.vstack(self.curr_predictions)\n",
    "                labels = torch.vstack(self.curr_labels)\n",
    "                print(\"/tTRAINING SET VALUES\")\n",
    "            else:\n",
    "                #Creating accumulators for test set\n",
    "                test_predict = []\n",
    "                test_labels = []\n",
    "                #Looping over each tensor and label in the dataloader\n",
    "                for batch_tensor, batch_label in dataloader:\n",
    "                    #Predicting using model on test set\n",
    "                    #print(\"IN THE ELSE STATEMENT TO TEST TEST SET\")\n",
    "                    prediction = self.model(batch_tensor)\n",
    "                    #accumulating model predictions and labels of test set\n",
    "                    test_predict.append(prediction)\n",
    "                    test_labels.append(batch_label)\n",
    "                    #print(f\"TEST PREDICT len:{len(test_predict)}\")\n",
    "                #Vstacking outputs and labels so that tensors read (patient x 1)\n",
    "                #Note loss function is MSE, so output from model will be a singular value that relates to our \n",
    "                #actual scale\n",
    "                #This differs from CrossEntropyLoss, where model output would be vector of length (num_classes)\n",
    "                #and each entry would be a probability of particular class\n",
    "                predict_output = torch.vstack(test_predict)\n",
    "                labels = torch.vstack(test_labels)\n",
    "                print(\"/tTEST SET VALUES\")\n",
    "            \n",
    "            #Squeezing output to get rid of nested tensors\n",
    "            predict_output = torch.squeeze(predict_output)\n",
    "            labels = torch.squeeze(labels)\n",
    "            \n",
    "            predict_output = torch.argmax(predict_output,axis = 1)\n",
    "            labels = torch.argmax(labels,axis = 1)\n",
    "            #Calculating loss of the model for train/test set\n",
    "            loss = self.loss_fn(predict_output.float(), labels.float())\n",
    "            #Calculating Mean Absolute Error based on train/test set\n",
    "            #print(f\"PREDICT_OUTPUT: {predict_output}\")\n",
    "            #print(f\"LABELS: {labels}\")\n",
    "            MAE = (predict_output.float() - labels.float()).abs().mean().item()\n",
    "            \n",
    "            #Rounding predicted output so that it matches the exact categories given by Norwood scale\n",
    "            #predict_output = torch.round(predict_output)\n",
    "            \n",
    "            #Calculating how many predictions were correct\n",
    "            num_correct = (predict_output == labels).sum().item()\n",
    "            \n",
    "            #Calculating accuracy of model\n",
    "            acc = num_correct / len(labels)\n",
    "            \n",
    "            print(f\"\\t\\t NUMBER CORRECT: {num_correct}\")\n",
    "            print(f\"\\t\\t ACCURACY: {acc}\")\n",
    "            print(f\"\\t\\t MEAN ABSOLUTE ERROR: {MAE}\")\n",
    "            print(f\"\\t\\t LOSS: {loss}\")\n",
    "            print(f\"\\t\\t PREDICTED: {predict_output}\")\n",
    "            print(f\"\\t\\t LABELS: {labels}\")\n",
    "            print(f\"++++++++++++++++++++++++++++++++++++++++++++++++++++\")                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6910eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom as dicom\n",
    "import math\n",
    "import time\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "        \n",
    "    def __init__(self, data_shape, dropout = .1):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        \n",
    "        #Get data shape\n",
    "        #self.in_channels, self.row_len, self.col_len = data_shape\n",
    "        self.row_len, self.col_len = data_shape\n",
    "        \n",
    "        self.learned_embedding = torch.zeros(data_shape)\n",
    "        self.learned_embedding = nn.Parameter(self.learned_embedding[None,:,:])\n",
    "                                              \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        \n",
    "        data = data + self.learned_embedding\n",
    "        data = self.dropout(data)\n",
    "        \n",
    "        return data\n",
    "\n",
    "class Convlayer(nn.Module):\n",
    "    \n",
    "    def __init__(self,data_shape:tuple,num_patches:int,output_dim:int = None):\n",
    "        super(Convlayer,self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        \n",
    "        self.batch,self.in_channels, self.row_len, self.col_len = data_shape\n",
    "        \n",
    "        assert self.row_len % num_patches == 0 \n",
    "        assert self.col_len % num_patches == 0\n",
    "        \n",
    "        \n",
    "        self.patch_row = self.row_len // num_patches\n",
    "        self.patch_col = self.col_len // num_patches\n",
    "        \n",
    "        self.embed_dim = int(self.in_channels * self.patch_row * self.patch_col)\n",
    "        \n",
    "        self.kernel_len = (int(self.patch_row), int(self.patch_col))\n",
    "        \n",
    "        patch_area = int(self.row_len * self.col_len)\n",
    "        \n",
    "        self.conv2d_1 = nn.Conv2d(in_channels = self.in_channels, \n",
    "                                  out_channels = self.embed_dim, \n",
    "                                  kernel_size =self. kernel_len, \n",
    "                                  stride = self.kernel_len)\n",
    "        \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten(start_dim=2) \n",
    "        if output_dim == None:\n",
    "            self.dnn = nn.Linear(self.embed_dim,self.embed_dim)\n",
    "        else:\n",
    "            self.output_dim = output_dim\n",
    "            self.dnn = nn.Linear(self.embed_dim,output_dim)\n",
    "    def forward(self,data):\n",
    "        \n",
    "        \n",
    "        #x = self.conv2d_1(data)\n",
    "        #print(x.shape)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.flatten(x)\n",
    "        #print(x.shape)\n",
    "        #x = torch.transpose(x,1,2)\n",
    "        #print(f'DATA SHAPE: {data.shape}')\n",
    "        batch = data.shape[0]\n",
    "        patches = data.unfold(2,self.row_len,self.row_len).unfold(3,self.col_len,self.col_len)\n",
    "        patches = torch.reshape(patches,(batch,self.num_patches**2,self.embed_dim))\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x = self.dnn(patches)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,data_shape,num_heads):\n",
    "        \n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        #self.batch, self.patch, self.embed = data_shape\n",
    "        self.patch, self.embed = data_shape\n",
    "        self.attn = nn.MultiheadAttention(self.embed,num_heads,batch_first = True)\n",
    "    def forward(self,data):\n",
    "        #data = torch.reshape(data,(data.shape[1],data.shape[2],data.shape[3]))\n",
    "        outputs , _ = self.attn(query=data, key=data, value=data, need_weights = False)\n",
    "        return outputs\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,data_shape,output_size,dropout = .1):\n",
    "        super(MLP,self).__init__()\n",
    "        #self.batch, self.patch, self.embed = data_shape\n",
    "        self.patch, self.embed = data_shape\n",
    "        hidden_output = self.embed * 2\n",
    "        self.lnn1 = nn.Linear(self.embed, hidden_output)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fnn2 = nn.Linear(hidden_output, output_size)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.gelu = nn.GELU()\n",
    "    def forward(self,data):\n",
    "        \n",
    "        x = self.lnn1(data)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fnn2(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "class TransformerEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,data_shape,num_heads,dropout=.1):\n",
    "        super(TransformerEncoder,self).__init__()\n",
    "        self.data_shape = data_shape\n",
    "        self.patch, self.embed = data_shape\n",
    "        #self.batch, self.patch, self.embed = data_shape\n",
    "        self.ln1 = nn.LayerNorm([self.patch,self.embed])\n",
    "        self.ln2 = nn.LayerNorm([self.patch,self.embed])\n",
    "        self.MHA = MultiHeadAttention(data_shape,num_heads)\n",
    "        self.mlp = MLP(data_shape, output_size = self.embed, dropout=dropout)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        \n",
    "        x = self.ln1(data)\n",
    "        att_out = self.MHA(x)\n",
    "        att_out = att_out + data\n",
    "        after_ln2 = self.ln2(att_out)\n",
    "        after_ln2 = self.mlp(after_ln2)\n",
    "        after_ln2 = after_ln2 + att_out\n",
    "        \n",
    "        return after_ln2\n",
    "        \n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self,data_shape,num_heads,num_layers = 6,dropout = .1):\n",
    "        super(VisionTransformer,self).__init__()\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                f'{i}', TransformerEncoder(data_shape=data_shape,num_heads = num_heads,dropout = dropout))\n",
    "    \n",
    "    def forward(self,data):\n",
    "        x = data\n",
    "        for blk in self.blks:\n",
    "            x = blk(x)\n",
    "        return x\n",
    "    \n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_layer,\n",
    "                 hidden_layer_1,\n",
    "                 hidden_layer_2,\n",
    "                 hidden_layer_3,\n",
    "                 hidden_layer_4,\n",
    "                 hidden_layer_5,\n",
    "                 num_output,\n",
    "                 dropout=.1):\n",
    "        super(ClassificationHead,self).__init__()\n",
    "        self.ln1 = nn.LayerNorm(input_layer)\n",
    "        self.fnn1 = nn.Linear(input_layer,hidden_layer_1)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.ln2 = nn.LayerNorm(hidden_layer_1)\n",
    "        self.fnn2 = nn.Linear(hidden_layer_1,hidden_layer_2)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.ln3 = nn.LayerNorm(hidden_layer_2)\n",
    "        self.fnn3 = nn.Linear(hidden_layer_2,hidden_layer_3)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        self.ln4 = nn.LayerNorm(hidden_layer_3)\n",
    "        self.fnn4 = nn.Linear(hidden_layer_3,hidden_layer_4)\n",
    "        self.dropout_4 = nn.Dropout(dropout)\n",
    "        self.ln5 = nn.LayerNorm(hidden_layer_4)\n",
    "        self.fnn5 = nn.Linear(hidden_layer_4,hidden_layer_5)\n",
    "        self.dropout_5 = nn.Dropout(dropout)\n",
    "        self.fnn6 = nn.Linear(hidden_layer_5,num_output)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        x = self.ln1(data)\n",
    "        x = self.fnn1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.fnn2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.ln3(x)\n",
    "        x = self.fnn3(x)\n",
    "        x = self.dropout_3(x)\n",
    "        x = self.ln4(x)\n",
    "        x = self.fnn4(x)\n",
    "        x = self.dropout_4(x)\n",
    "        x = self.ln5(x)\n",
    "        x = self.fnn5(x)\n",
    "        x = self.dropout_5(x)\n",
    "        x = self.fnn6(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class PRPModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 data_shape,\n",
    "                 num_patch:int,\n",
    "                 num_heads,\n",
    "                 num_output,\n",
    "                 num_layers,\n",
    "                 conv_output_dim,\n",
    "                 hidden_layer_1,\n",
    "                 hidden_layer_2,\n",
    "                 hidden_layer_3,\n",
    "                 hidden_layer_4,\n",
    "                 hidden_layer_5,\n",
    "                dropout = .1):\n",
    "        super(PRPModel,self).__init__()\n",
    "        self.batch_size = data_shape[0]\n",
    "        self.data_shape = data_shape[1:]\n",
    "        \n",
    "        self.conv_layer = Convlayer(data_shape,num_patch,conv_output_dim)\n",
    "        self.in_channels, self.row_len, self.col_len = self.data_shape\n",
    "        assert self.row_len % num_patch == 0 \n",
    "        assert self.col_len % num_patch == 0\n",
    "        \n",
    "        patch_row = self.row_len // num_patch\n",
    "        patch_col = self.col_len // num_patch\n",
    "        \n",
    "        embed_dim = patch_row * patch_col * self.in_channels\n",
    "        assert embed_dim % num_heads == 0, f\"embed_dimension is not divisible by num_heads \\nembed_dim: {embed_dim},heads:{num_heads}\"\n",
    "        \n",
    "        #self.data_shape = (self.batch_size,num_patch**2,patch_row * patch_col * self.in_channels)\n",
    "        self.data_shape = (num_patch**2,patch_row * patch_col * self.in_channels)\n",
    "        \n",
    "        self.pos_encode = PositionalEncoding(self.data_shape,dropout)\n",
    "        \n",
    "        \n",
    "        self.visual_transformer = VisionTransformer(self.data_shape,num_heads,num_layers,dropout)\n",
    "        \n",
    "        #self.input_layer = self.data_shape[1] * self.data_shape[2]\n",
    "        #self.input_layer = self.data_shape[0] * self.data_shape[1]\n",
    "        self.input_layer = self.data_shape[0] * self.data_shape[1]\n",
    "        \n",
    "        #self.ClassificationHead = ClassificationHead(self.input_layer,\n",
    "                                                     #hidden_layer_1,\n",
    "                                                     #hidden_layer_2,\n",
    "                                                     #hidden_layer_3,\n",
    "                                                     #num_output,\n",
    "                                                     #dropout=.1)\n",
    "                            \n",
    "        self.ClassificationHead = ClassificationHead(self.data_shape[1],\n",
    "                                                     hidden_layer_1,\n",
    "                                                     hidden_layer_2,\n",
    "                                                     hidden_layer_3,\n",
    "                                                     hidden_layer_4,\n",
    "                                                     hidden_layer_5,\n",
    "                                                     num_output,\n",
    "                                                     dropout=.1)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self,data):\n",
    "        batch_size = data.shape[0]\n",
    "        \n",
    "        x = self.conv_layer(data)\n",
    "        x = self.pos_encode(x)\n",
    "        x = self.visual_transformer(x)\n",
    "        #print(x.shape)\n",
    "        #x = torch.reshape(x,(batch_size,self.input_layer))\n",
    "        x = torch.squeeze(x[:,-1,:])\n",
    "        x = self.ClassificationHead(x)\n",
    "        #print(f\"BEFORE SOFTMAX: {x}\")\n",
    "        x = self.softmax(x)\n",
    "        #x = torch.argmax(x,axis = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f4c1c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1600])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5,1600)[-1,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07e7f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dict_path: str,\n",
    "        data_path:str,\n",
    "        batch_size: int ,\n",
    "        sequential : bool , \n",
    "        split: tuple , \n",
    "        image_size: tuple,\n",
    "        num_patch: int,\n",
    "        num_heads: int,\n",
    "        vision_num_layers :int,\n",
    "        conv_output_dim:int,\n",
    "        hidden_layer_1:int,\n",
    "        hidden_layer_2:int,\n",
    "        hidden_layer_3:int,\n",
    "        hidden_layer_4:int,\n",
    "        hidden_layer_5:int,\n",
    "        num_classification_output : int,\n",
    "        dropout: float,\n",
    "        save_interval:int,\n",
    "        metric_interval:int,\n",
    "        save_path:str,\n",
    "        num_epochs:int\n",
    "               ):\n",
    "    train_data , test_data = PRPDataLoader(dict_path,data_path,num_classification_output,image_size,sequential,split,batch_size)\n",
    "    in_channels, row_len, col_len = 4, image_size[0], image_size[1]\n",
    "    \n",
    "    assert row_len % num_patch == 0, 'row_len not divisible by num_patches' \n",
    "    assert col_len % num_patch == 0, \"col_len not divisible by num_patches\"\n",
    "        \n",
    "    patch_row = row_len // num_patch\n",
    "    patch_col = col_len // num_patch\n",
    "    embed_dim = patch_row * patch_col * in_channels\n",
    "    assert embed_dim % num_heads == 0, \"embed_dimension is not divisible by num_heads\"\n",
    "\n",
    "    model = PRPModel((batch_size,4,image_size[0],image_size[1]),\n",
    "                     num_patch,\n",
    "                     num_heads,\n",
    "                     num_classification_output,\n",
    "                     vision_num_layers,\n",
    "                     conv_output_dim,\n",
    "                     hidden_layer_1,\n",
    "                     hidden_layer_2,\n",
    "                     hidden_layer_3,\n",
    "                     hidden_layer_4,\n",
    "                     hidden_layer_5,\n",
    "                     dropout)\n",
    "    \n",
    "    adam_optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    \n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "    trainer = Trainer(model,adam_optimizer,mse_loss,save_interval,metric_interval,train_data,test_data= test_data,save_path = save_path)\n",
    "\n",
    "    trainer.train(num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8db6949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 1 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 2\n",
      "\t\t ACCURACY: 0.25\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 7.75\n",
      "\t\t PREDICTED: tensor([5, 6, 6, 1, 6, 0, 0, 6])\n",
      "\t\t LABELS: tensor([1, 5, 6, 3, 0, 1, 0, 4])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.0\n",
      "\t\t LOSS: 1.0\n",
      "\t\t PREDICTED: tensor([1, 1])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 2 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 1\n",
      "\t\t ACCURACY: 0.125\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.125\n",
      "\t\t LOSS: 6.625\n",
      "\t\t PREDICTED: tensor([1, 1, 1, 1, 1, 2, 4, 4])\n",
      "\t\t LABELS: tensor([6, 1, 4, 0, 3, 0, 1, 5])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.0\n",
      "\t\t LOSS: 1.0\n",
      "\t\t PREDICTED: tensor([1, 1])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 3 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 2\n",
      "\t\t ACCURACY: 0.25\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.375\n",
      "\t\t LOSS: 9.875\n",
      "\t\t PREDICTED: tensor([0, 1, 0, 1, 1, 0, 0, 0])\n",
      "\t\t LABELS: tensor([3, 5, 4, 0, 1, 6, 0, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 4 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 2\n",
      "\t\t ACCURACY: 0.25\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.5\n",
      "\t\t LOSS: 11.0\n",
      "\t\t PREDICTED: tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\t\t LABELS: tensor([4, 3, 6, 0, 5, 1, 1, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 5 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 3\n",
      "\t\t ACCURACY: 0.375\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 8.75\n",
      "\t\t PREDICTED: tensor([0, 6, 0, 0, 0, 0, 1, 1])\n",
      "\t\t LABELS: tensor([5, 4, 1, 6, 0, 0, 3, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.0\n",
      "\t\t LOSS: 1.0\n",
      "\t\t PREDICTED: tensor([1, 1])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 6 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 3\n",
      "\t\t ACCURACY: 0.375\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.875\n",
      "\t\t LOSS: 6.875\n",
      "\t\t PREDICTED: tensor([1, 0, 0, 1, 1, 1, 0, 1])\n",
      "\t\t LABELS: tensor([4, 1, 0, 6, 3, 5, 0, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 2\n",
      "\t\t ACCURACY: 1.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.0\n",
      "\t\t LOSS: 0.0\n",
      "\t\t PREDICTED: tensor([2, 2])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 7 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.25\n",
      "\t\t LOSS: 6.0\n",
      "\t\t PREDICTED: tensor([2, 2, 1, 0, 1, 2, 2, 2])\n",
      "\t\t LABELS: tensor([0, 6, 4, 1, 3, 1, 5, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 8 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 3\n",
      "\t\t ACCURACY: 0.375\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.875\n",
      "\t\t LOSS: 7.375\n",
      "\t\t PREDICTED: tensor([1, 0, 1, 2, 2, 0, 0, 1])\n",
      "\t\t LABELS: tensor([1, 0, 4, 1, 5, 6, 0, 3])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 9 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 3\n",
      "\t\t ACCURACY: 0.375\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 9.0\n",
      "\t\t PREDICTED: tensor([0, 1, 0, 0, 1, 4, 0, 0])\n",
      "\t\t LABELS: tensor([5, 1, 0, 1, 4, 3, 0, 6])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 10 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 6\n",
      "\t\t ACCURACY: 0.75\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.25\n",
      "\t\t LOSS: 6.25\n",
      "\t\t PREDICTED: tensor([6, 0, 1, 3, 4, 6, 0, 0])\n",
      "\t\t LABELS: tensor([1, 5, 1, 3, 4, 6, 0, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 11 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 3\n",
      "\t\t ACCURACY: 0.375\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.875\n",
      "\t\t LOSS: 6.875\n",
      "\t\t PREDICTED: tensor([6, 6, 0, 6, 0, 6, 3, 0])\n",
      "\t\t LABELS: tensor([5, 1, 0, 6, 4, 3, 1, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 12 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 3\n",
      "\t\t ACCURACY: 0.375\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.875\n",
      "\t\t LOSS: 8.375\n",
      "\t\t PREDICTED: tensor([0, 6, 3, 0, 6, 0, 3, 3])\n",
      "\t\t LABELS: tensor([0, 5, 1, 0, 1, 6, 3, 4])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 13 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 3\n",
      "\t\t ACCURACY: 0.375\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.375\n",
      "\t\t LOSS: 5.375\n",
      "\t\t PREDICTED: tensor([0, 6, 3, 3, 0, 3, 0, 0])\n",
      "\t\t LABELS: tensor([6, 5, 1, 4, 1, 3, 0, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 14 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 3\n",
      "\t\t ACCURACY: 0.375\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.875\n",
      "\t\t LOSS: 8.375\n",
      "\t\t PREDICTED: tensor([3, 0, 0, 3, 0, 3, 0, 0])\n",
      "\t\t LABELS: tensor([3, 1, 6, 1, 0, 4, 0, 5])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 15 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 4\n",
      "\t\t ACCURACY: 0.5\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.875\n",
      "\t\t LOSS: 8.875\n",
      "\t\t PREDICTED: tensor([0, 4, 0, 0, 0, 3, 4, 0])\n",
      "\t\t LABELS: tensor([0, 1, 1, 6, 0, 3, 4, 5])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 16 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 4\n",
      "\t\t ACCURACY: 0.5\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.125\n",
      "\t\t LOSS: 10.125\n",
      "\t\t PREDICTED: tensor([0, 0, 4, 0, 0, 3, 3, 5])\n",
      "\t\t LABELS: tensor([5, 0, 4, 6, 0, 1, 3, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.5\n",
      "\t\t LOSS: 6.5\n",
      "\t\t PREDICTED: tensor([5, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 17 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 5\n",
      "\t\t ACCURACY: 0.625\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.875\n",
      "\t\t LOSS: 2.625\n",
      "\t\t PREDICTED: tensor([0, 5, 4, 3, 6, 0, 4, 5])\n",
      "\t\t LABELS: tensor([0, 1, 4, 1, 6, 0, 3, 5])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.5\n",
      "\t\t LOSS: 6.5\n",
      "\t\t PREDICTED: tensor([0, 5])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 18 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 5\n",
      "\t\t ACCURACY: 0.625\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.75\n",
      "\t\t LOSS: 1.75\n",
      "\t\t PREDICTED: tensor([4, 4, 5, 0, 0, 3, 3, 5])\n",
      "\t\t LABELS: tensor([4, 1, 5, 0, 0, 1, 3, 6])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 2.5\n",
      "\t\t PREDICTED: tensor([0, 3])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 19 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 4\n",
      "\t\t ACCURACY: 0.5\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.875\n",
      "\t\t LOSS: 1.625\n",
      "\t\t PREDICTED: tensor([3, 3, 4, 3, 3, 0, 0, 5])\n",
      "\t\t LABELS: tensor([1, 3, 4, 1, 5, 0, 0, 6])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.5\n",
      "\t\t LOSS: 6.5\n",
      "\t\t PREDICTED: tensor([5, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 20 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 4\n",
      "\t\t ACCURACY: 0.5\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.0\n",
      "\t\t LOSS: 2.75\n",
      "\t\t PREDICTED: tensor([5, 0, 3, 3, 5, 3, 0, 5])\n",
      "\t\t LABELS: tensor([6, 0, 1, 4, 5, 3, 0, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.5\n",
      "\t\t LOSS: 6.5\n",
      "\t\t PREDICTED: tensor([0, 5])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 21 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 5\n",
      "\t\t ACCURACY: 0.625\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 7.0\n",
      "\t\t PREDICTED: tensor([0, 4, 5, 5, 3, 0, 3, 0])\n",
      "\t\t LABELS: tensor([0, 4, 1, 5, 3, 0, 1, 6])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 22 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 6\n",
      "\t\t ACCURACY: 0.75\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.0\n",
      "\t\t LOSS: 5.0\n",
      "\t\t PREDICTED: tensor([1, 4, 0, 5, 0, 1, 1, 0])\n",
      "\t\t LABELS: tensor([1, 4, 0, 5, 6, 3, 1, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 23 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 5\n",
      "\t\t ACCURACY: 0.625\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.125\n",
      "\t\t LOSS: 5.125\n",
      "\t\t PREDICTED: tensor([1, 0, 1, 6, 1, 4, 0, 0])\n",
      "\t\t LABELS: tensor([1, 6, 3, 5, 1, 4, 0, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 24 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 6\n",
      "\t\t ACCURACY: 0.75\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.25\n",
      "\t\t LOSS: 6.5\n",
      "\t\t PREDICTED: tensor([0, 3, 0, 0, 1, 1, 4, 1])\n",
      "\t\t LABELS: tensor([0, 3, 6, 0, 1, 1, 4, 5])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 2.5\n",
      "\t\t PREDICTED: tensor([0, 1])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 25 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 6\n",
      "\t\t ACCURACY: 0.75\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.125\n",
      "\t\t LOSS: 5.125\n",
      "\t\t PREDICTED: tensor([4, 1, 0, 1, 0, 3, 1, 1])\n",
      "\t\t LABELS: tensor([4, 1, 0, 6, 0, 3, 5, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 2.5\n",
      "\t\t PREDICTED: tensor([0, 1])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 26 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 5\n",
      "\t\t ACCURACY: 0.625\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.375\n",
      "\t\t LOSS: 0.375\n",
      "\t\t PREDICTED: tensor([1, 4, 5, 0, 4, 1, 0, 6])\n",
      "\t\t LABELS: tensor([1, 4, 6, 0, 3, 1, 0, 5])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 27 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([1, 4, 5, 3, 1, 0, 5, 0])\n",
      "\t\t LABELS: tensor([1, 4, 6, 3, 1, 0, 5, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 28 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([1, 4, 5, 3, 0, 0, 5, 1])\n",
      "\t\t LABELS: tensor([1, 4, 5, 3, 0, 0, 6, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 29 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.75\n",
      "\t\t LOSS: 4.5\n",
      "\t\t PREDICTED: tensor([0, 3, 5, 4, 1, 0, 0, 1])\n",
      "\t\t LABELS: tensor([0, 3, 5, 4, 1, 0, 6, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 30 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 8\n",
      "\t\t ACCURACY: 1.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.0\n",
      "\t\t LOSS: 0.0\n",
      "\t\t PREDICTED: tensor([6, 1, 0, 1, 0, 3, 5, 4])\n",
      "\t\t LABELS: tensor([6, 1, 0, 1, 0, 3, 5, 4])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.5\n",
      "\t\t LOSS: 8.5\n",
      "\t\t PREDICTED: tensor([1, 6])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 31 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([4, 0, 1, 5, 3, 1, 5, 0])\n",
      "\t\t LABELS: tensor([4, 0, 1, 6, 3, 1, 5, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 32 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 5\n",
      "\t\t ACCURACY: 0.625\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.75\n",
      "\t\t LOSS: 2.25\n",
      "\t\t PREDICTED: tensor([3, 5, 0, 1, 0, 0, 6, 1])\n",
      "\t\t LABELS: tensor([3, 6, 0, 1, 4, 0, 5, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 33 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.5\n",
      "\t\t LOSS: 2.0\n",
      "\t\t PREDICTED: tensor([1, 0, 4, 1, 0, 6, 1, 3])\n",
      "\t\t LABELS: tensor([5, 0, 4, 1, 0, 6, 1, 3])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 34 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([4, 0, 3, 6, 0, 1, 1, 6])\n",
      "\t\t LABELS: tensor([4, 0, 3, 6, 0, 1, 1, 5])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 35 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([6, 1, 0, 0, 4, 1, 6, 3])\n",
      "\t\t LABELS: tensor([6, 1, 0, 0, 4, 1, 5, 3])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 3.0\n",
      "\t\t LOSS: 10.0\n",
      "\t\t PREDICTED: tensor([6, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 36 epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 8\n",
      "\t\t ACCURACY: 1.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.0\n",
      "\t\t LOSS: 0.0\n",
      "\t\t PREDICTED: tensor([1, 3, 6, 0, 1, 5, 4, 0])\n",
      "\t\t LABELS: tensor([1, 3, 6, 0, 1, 5, 4, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 2.5\n",
      "\t\t PREDICTED: tensor([1, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 37 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([5, 0, 1, 5, 3, 0, 1, 4])\n",
      "\t\t LABELS: tensor([6, 0, 1, 5, 3, 0, 1, 4])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 3.0\n",
      "\t\t LOSS: 10.0\n",
      "\t\t PREDICTED: tensor([0, 6])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 38 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 6\n",
      "\t\t ACCURACY: 0.75\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.25\n",
      "\t\t LOSS: 0.25\n",
      "\t\t PREDICTED: tensor([1, 0, 4, 5, 5, 4, 1, 0])\n",
      "\t\t LABELS: tensor([1, 0, 4, 5, 6, 3, 1, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 39 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 5\n",
      "\t\t ACCURACY: 0.625\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 7.75\n",
      "\t\t PREDICTED: tensor([4, 0, 0, 1, 4, 0, 0, 1])\n",
      "\t\t LABELS: tensor([4, 6, 0, 1, 3, 0, 5, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 2.5\n",
      "\t\t PREDICTED: tensor([1, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 40 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 6\n",
      "\t\t ACCURACY: 0.75\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.75\n",
      "\t\t LOSS: 3.25\n",
      "\t\t PREDICTED: tensor([1, 4, 1, 0, 0, 5, 1, 4])\n",
      "\t\t LABELS: tensor([1, 3, 6, 0, 0, 5, 1, 4])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 2.5\n",
      "\t\t PREDICTED: tensor([0, 1])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 41 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([5, 1, 3, 0, 4, 1, 5, 0])\n",
      "\t\t LABELS: tensor([6, 1, 3, 0, 4, 1, 5, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 2.5\n",
      "\t\t PREDICTED: tensor([0, 1])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 42 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([4, 0, 1, 5, 5, 1, 3, 0])\n",
      "\t\t LABELS: tensor([4, 0, 1, 5, 6, 1, 3, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 1.5\n",
      "\t\t LOSS: 2.5\n",
      "\t\t PREDICTED: tensor([1, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 43 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([3, 1, 5, 0, 0, 1, 4, 5])\n",
      "\t\t LABELS: tensor([3, 1, 5, 0, 0, 1, 4, 6])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 44 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([4, 1, 5, 1, 5, 3, 0, 0])\n",
      "\t\t LABELS: tensor([4, 1, 6, 1, 5, 3, 0, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 45 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.625\n",
      "\t\t LOSS: 3.125\n",
      "\t\t PREDICTED: tensor([4, 0, 1, 5, 1, 3, 1, 0])\n",
      "\t\t LABELS: tensor([4, 0, 1, 5, 1, 3, 6, 0])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 46 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 7\n",
      "\t\t ACCURACY: 0.875\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.125\n",
      "\t\t LOSS: 0.125\n",
      "\t\t PREDICTED: tensor([5, 1, 4, 3, 0, 1, 0, 5])\n",
      "\t\t LABELS: tensor([6, 1, 4, 3, 0, 1, 0, 5])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 47 epoch\n",
      "/tTRAINING SET VALUES\n",
      "\t\t NUMBER CORRECT: 6\n",
      "\t\t ACCURACY: 0.75\n",
      "\t\t MEAN ABSOLUTE ERROR: 0.25\n",
      "\t\t LOSS: 0.25\n",
      "\t\t PREDICTED: tensor([0, 3, 5, 5, 1, 3, 0, 1])\n",
      "\t\t LABELS: tensor([0, 3, 5, 6, 1, 4, 0, 1])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "/tTEST SET VALUES\n",
      "\t\t NUMBER CORRECT: 0\n",
      "\t\t ACCURACY: 0.0\n",
      "\t\t MEAN ABSOLUTE ERROR: 2.0\n",
      "\t\t LOSS: 4.0\n",
      "\t\t PREDICTED: tensor([0, 0])\n",
      "\t\t LABELS: tensor([2, 2])\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "running 48 epoch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m     \u001b[49m\u001b[43msequential\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m     \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m     \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnum_patch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m     \u001b[49m\u001b[43mvision_num_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m     \u001b[49m\u001b[43mconv_output_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhidden_layer_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhidden_layer_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhidden_layer_3\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhidden_layer_4\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhidden_layer_5\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnum_classification_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m     \u001b[49m\u001b[43msave_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmetric_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m     \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dict_path, data_path, batch_size, sequential, split, image_size, num_patch, num_heads, vision_num_layers, conv_output_dim, hidden_layer_1, hidden_layer_2, hidden_layer_3, hidden_layer_4, hidden_layer_5, num_classification_output, dropout, save_interval, metric_interval, save_path, num_epochs)\u001b[0m\n\u001b[1;32m     50\u001b[0m mse_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     52\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model,adam_optimizer,mse_loss,save_interval,metric_interval,train_data,test_data\u001b[38;5;241m=\u001b[39m test_data,save_path \u001b[38;5;241m=\u001b[39m save_path)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    143\u001b[0m     \n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m#Running an epoch\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m#print(\"outside self.save_interval\")\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m#Code to save the model every save_interval   \u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_interval \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;66;03m#print(\"In save_interval\")\u001b[39;00m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mTrainer._run_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m#Looping over each training batch\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m#print(\"training model\")\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_tensor, batch_labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data:\n\u001b[1;32m    114\u001b[0m     \n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m#print(f\"batch_tensor: {batch_tensor.shape}\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m#Running gradient descent on each batch\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mTrainer._run_batch\u001b[0;34m(self, batch, batch_labels)\u001b[0m\n\u001b[1;32m     92\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(pred_output\u001b[38;5;241m.\u001b[39mfloat(),batch_labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m#Computing gradient for each parameter in model\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m#grads = [p.grad for p in self.model.parameters()]\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#print(grads[:50])\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#Gradient descent \u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(dict_path = \"test_dict\",\n",
    "     data_path = \"\",\n",
    "     batch_size = 5,\n",
    "     sequential = False,\n",
    "     split = (.8,.2),\n",
    "     image_size = (300,300),\n",
    "     num_patch = 30,\n",
    "     num_heads = 5,\n",
    "     vision_num_layers = 8,\n",
    "     conv_output_dim = None,\n",
    "     hidden_layer_1 = 1600,\n",
    "     hidden_layer_2 = 800,\n",
    "     hidden_layer_3 = 400,\n",
    "     hidden_layer_4 = 100,\n",
    "     hidden_layer_5 = 25,\n",
    "     num_classification_output = 7,\n",
    "     dropout = .1,\n",
    "     save_interval = 1000000,\n",
    "     metric_interval = 1,\n",
    "     save_path = \"\",\n",
    "     num_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d5c57b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d7d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\"vertex1\" : 1, \"vertex2\" : 2, \"vertex3\": 3,\"vertex4\":4,\n",
    "             \"vertex5\":5,\"vertex6\":6,\"vertex7\":7,\"vertex8\":1,\"vertex9\":2,\"vertex10\":3}\n",
    "cPickle.dump(test_dict, open(f'test_dict', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "11bcd305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 10, 200, 20])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,4,200,200)\n",
    "patches = x.unfold(2, 20, 20)\n",
    "print(patches.shape)\n",
    "patches = patches.unfold(3, 20, 20)\n",
    "\n",
    "patches = torch.reshape(patches,(2,100,4 * 20 * 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "51aeb947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1600])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "548332a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 200, 20])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice.unfold(1,20,20).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
